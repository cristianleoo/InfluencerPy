{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to InfluencerPy","text":"<p>Intelligent Content Discovery &amp; Curation, Powered by AI</p> <p>InfluencerPy is an AI-powered tool that helps you discover, monitor, and curate the best content from across the web. Using intelligent scouts, it continuously finds relevant content, summarizes key insights, and optionally generates social media posts.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\ud83d\udd0d Smart Content Discovery: Create AI scouts that monitor RSS, Reddit, Substack, Arxiv, and more</li> <li>\ud83d\udccb Curated Reports: Get organized lists with summaries and links to original sources</li> <li>\ud83e\udd16 AI-Powered: Uses Gemini or Anthropic for intelligent content selection and summarization</li> <li>\u270d\ufe0f Optional Post Generation: Turn discovered content into social media posts for X (Twitter)</li> <li>\ud83d\udcf1 Telegram Delivery: Receive scout reports and review drafts from your phone</li> <li>\ud83d\udcc5 Smart Scheduling: Set scouts to run automatically (daily, weekly, custom)</li> <li>\ud83e\udde0 Self-Improving: Learns from your feedback to optimize content selection</li> </ul>"},{"location":"#two-modes-of-operation","title":"Two Modes of Operation","text":""},{"location":"#scouting-mode-primary","title":"\ud83d\udd0d Scouting Mode (Primary)","text":"<p>Find and list interesting content with summaries and links. Perfect for:</p> <ul> <li>Research and staying informed in your field</li> <li>Competitive intelligence</li> <li>Newsletter curation</li> <li>Content discovery for teams</li> </ul>"},{"location":"#generation-mode-optional","title":"\u270d\ufe0f Generation Mode (Optional)","text":"<p>Automatically create social media posts from discovered content. Great for:</p> <ul> <li>Maintaining active social presence</li> <li>Content repurposing</li> <li>Automated Twitter accounts</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>git clone https://github.com/cristianleoo/InfluencerPy.git\ncd InfluencerPy\npip install -e .\ninfluencerpy\n</code></pre>"},{"location":"#examples-tutorials","title":"Examples &amp; Tutorials","text":"<p>Check out practical examples and step-by-step tutorials to get started quickly:</p>"},{"location":"#complete-tutorials","title":"\ud83d\udcda Complete Tutorials","text":"<p>Multi-Feed RSS Scout Example</p> <p>Comprehensive guide for creating a content discovery scout that monitors multiple RSS feeds simultaneously. Learn how to:</p> <ul> <li>Add multiple RSS feeds in one scout (comma-separated)</li> <li>Monitor 5+ sources with a single daily digest  </li> <li>Understand multi-feed behavior and AI selection</li> <li>Customize and troubleshoot your scout</li> </ul> <p>Real-world use case: AI Research Digest monitoring Berkeley, Google, MIT, Microsoft, and Takara AI feeds.</p> <p>Multi-Feed RSS Visual Guide</p> <p>Step-by-step walkthrough with command-line examples showing exactly what you'll see when creating and running a multi-feed scout. Perfect for visual learners!</p>"},{"location":"#code-examples","title":"\ud83d\udee0\ufe0f Code Examples","text":"<p>HTTP Tool Demo</p> <p>Demonstrates web scraping and content extraction using the HTTP Request tool:</p> <pre><code>from influencerpy.tools.http_tool import http_request\n\n# Fetch a webpage\nresult = http_request(url=\"https://example.com\")\nprint(f\"Title: {result['title']}\")\nprint(f\"Content: {result['content'][:200]}...\")\n\n# Extract specific content with CSS selectors\nresult = http_request(\n    url=\"https://en.wikipedia.org/wiki/Web_scraping\",\n    selector=\"#mw-content-text\"\n)\n\n# Extract all links from a page\nresult = http_request(\n    url=\"https://news.ycombinator.com\",\n    extract_links=True\n)\nfor link in result['links'][:5]:\n    print(f\"{link['text']}: {link['url']}\")\n</code></pre> <p>Run the full demo:</p> <pre><code>python examples/http_tool_demo.py\n</code></pre> <p>Features demonstrated:</p> <ul> <li>Basic URL fetching and parsing</li> <li>CSS selector usage for targeted content</li> <li>Link extraction from pages</li> <li>Error handling</li> </ul>"},{"location":"#quick-start-example","title":"\ud83d\ude80 Quick Start Example","text":"<p>Here's a quick example of creating a scout to monitor AI research from multiple sources:</p> <pre><code># Run influencerpy and choose \"Create Scout\"\n# Then configure:\n\nScout Name: AI Research Digest\nIntent: \ud83d\udd0d Content Discovery (Scouting)\nScout Type: \ud83d\udce1 RSS\nRSS Feed URLs: https://tldr.takara.ai/api/papers, https://bair.berkeley.edu/blog/feed.xml, https://research.google/blog/rss/, https://news.mit.edu/rss/topic/artificial-intelligence2, https://news.microsoft.com/source/topics/ai/feed/\nSchedule: Daily at 9:00 AM\n</code></pre> <p>Tip: You can add multiple RSS feeds at once by separating them with commas! This example monitors 5 different AI research sources.</p> <p>The scout will:</p> <ol> <li>Monitor 5 AI research feeds simultaneously (Berkeley, Google, MIT, Microsoft, Takara)</li> <li>Use AI to analyze and select the most relevant articles across all sources</li> <li>Send a curated list to your Telegram with summaries and links</li> <li>Run automatically every day at 9 AM</li> </ol> <p>\ud83d\udcd6 For detailed step-by-step instructions, see the Multi-Feed RSS Scout Example.</p> <p>More Examples: Check out the examples directory for additional tutorials and code samples.</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Getting Started: Installation and initial setup</li> <li>Understanding Scouts: Learn about scouting vs generation intents</li> <li>Telegram Integration: Setup Telegram for scout reports</li> <li>Scheduling: Automate your content pipeline</li> </ul>"},{"location":"deployment/","title":"Deployment Guide","text":"<p>InfluencerPy is designed to run continuously in the background to monitor feeds and manage your social media presence. This guide covers how to keep it running and where to host it for free.</p>"},{"location":"deployment/#running-in-the-background","title":"Running in the Background","text":"<p>Since InfluencerPy is a CLI application, closing your terminal will stop the bot. Here are two ways to keep it running.</p>"},{"location":"deployment/#langfuse-tracing-optional","title":"Langfuse Tracing (Optional)","text":"<p>To enable observability for your scouts via Langfuse: 1.  Sign up at Langfuse. 2.  Get your API keys (Base URL, Public Key, Secret Key). 3.  Easy Setup: Run <code>influencerpy</code> and select \"Configure Credentials\" -&gt; \"Langfuse (Tracing)\". 4.  Manual Setup: Add them to your <code>.env</code> file:     <pre><code>LANGFUSE_HOST=\"https://cloud.langfuse.com\"\nLANGFUSE_PUBLIC_KEY=\"pk-lf-...\"\nLANGFUSE_SECRET_KEY=\"sk-lf-...\"\n</code></pre> 5.  When creating a scout, you can enable tracing. If keys are missing, the CLI will offer to help you set them up.</p>"},{"location":"deployment/#option-1-using-tmux-recommended-for-beginners","title":"Option 1: Using <code>tmux</code> (Recommended for Beginners)","text":"<p><code>tmux</code> allows you to create a session that keeps running even after you disconnect from your server.</p> <ol> <li> <p>Install tmux:     <pre><code># Ubuntu/Debian\nsudo apt install tmux\n\n# macOS\nbrew install tmux\n</code></pre></p> </li> <li> <p>Start a new session:     <pre><code>tmux new -s influencerpy\n</code></pre></p> </li> <li> <p>Run the bot:     <pre><code>influencerpy bot\n</code></pre></p> </li> <li> <p>Detach: Press <code>Ctrl+B</code> then <code>D</code>. You can now safely close your terminal.</p> </li> <li> <p>Reattach: To check on your bot later:     <pre><code>tmux attach -s influencerpy\n</code></pre></p> </li> </ol>"},{"location":"deployment/#option-2-using-systemd-recommended-for-production","title":"Option 2: Using <code>systemd</code> (Recommended for Production)","text":"<p>For a more robust setup on Linux servers, use <code>systemd</code> to automatically restart the bot if it crashes or the server reboots.</p> <ol> <li> <p>Create a service file:     <pre><code>sudo nano /etc/systemd/system/influencerpy.service\n</code></pre></p> </li> <li> <p>Add the following configuration (adjust paths and user):     <pre><code>[Unit]\nDescription=InfluencerPy Bot\nAfter=network.target\n\n[Service]\nType=simple\nUser=your_username\nWorkingDirectory=/home/your_username/InfluencerPy\n# Ensure the path to 'influencerpy' is correct (e.g., inside venv)\nExecStart=/home/your_username/InfluencerPy/.venv/bin/influencerpy bot\nRestart=always\nRestartSec=10\nEnvironmentFile=/home/your_username/InfluencerPy/.env\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></p> </li> <li> <p>Enable and Start:     <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable influencerpy\nsudo systemctl start influencerpy\n</code></pre></p> </li> <li> <p>Check Logs:     <pre><code>sudo journalctl -u influencerpy -f\n</code></pre></p> </li> </ol>"},{"location":"deployment/#free-hosting-options","title":"Free Hosting Options","text":"<p>You don't need an expensive server to run InfluencerPy. Here are some excellent free options:</p>"},{"location":"deployment/#1-oracle-cloud-free-tier-best-performance","title":"1. Oracle Cloud Free Tier (Best Performance)","text":"<p>Oracle offers \"Always Free\" ARM instances that are very powerful. *   Specs: Up to 4 ARM Ampere CPUs and 24GB RAM. *   Pros: extremely generous resources, fast network. *   Cons: Sign-up can be picky about credit cards.</p>"},{"location":"deployment/#2-google-cloud-platform-gcp-free-tier","title":"2. Google Cloud Platform (GCP) Free Tier","text":"<ul> <li>Specs: e2-micro instance (2 vCPUs, 1GB RAM).</li> <li>Pros: Reliable, easy integration with other Google services.</li> <li>Cons: Limited RAM (might need swap file).</li> </ul>"},{"location":"deployment/#3-aws-free-tier","title":"3. AWS Free Tier","text":"<ul> <li>Specs: t2.micro or t3.micro (1 vCPU, 1GB RAM) for 12 months.</li> <li>Pros: Industry standard.</li> <li>Cons: Free trial expires after 1 year.</li> </ul>"},{"location":"deployment/#4-digitalocean-droplets","title":"4. DigitalOcean (Droplets)","text":"<p>DigitalOcean provides affordable VPS options. *   Pros: Simple deployment, good documentation. *   Cons: No permanent free tier (but very affordable starting at $4/month).</p>"},{"location":"deployment/#tips-for-cloud-deployment","title":"Tips for Cloud Deployment","text":"<ul> <li>Environment Variables: Ensure your <code>.env</code> file is securely copied to the server or variables are set in the deployment environment.</li> <li>Database: By default, InfluencerPy uses SQLite (<code>database.db</code>). If you redeploy or destroy the instance, you will lose data unless you use a persistent volume or switch to a cloud database (PostgreSQL).</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following:</p> <ol> <li>Python 3.9 or higher: Check with <code>python --version</code>.</li> <li>Telegram Bot (Required): Used to receive scout reports and review drafts.<ul> <li>Message <code>@BotFather</code> to create a bot and get your Bot Token</li> <li>Message <code>@userinfobot</code> to get your Chat ID</li> </ul> </li> <li>API Keys: You will need API keys depending on your use case:<ul> <li>Google Gemini API Key (Required for AI features): Get it from Google AI Studio.</li> <li>X (Twitter) API Keys (Optional, only for posting): You need a Developer Account with \"Read and Write\" permissions. Get them from the X Developer Portal.</li> <li>Substack Cookies (Optional, only for paywalled content): See the Substack Setup Guide for details.</li> </ul> </li> </ol>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#installation_1","title":"Installation","text":"<p>InfluencerPy is currently available via source installation.</p> <ol> <li> <p>Clone the repository:     <pre><code>git clone https://github.com/cristianleoo/InfluencerPy.git\ncd InfluencerPy\n</code></pre></p> </li> <li> <p>Install dependencies:     <pre><code>pip install -e .\n</code></pre></p> </li> </ol>"},{"location":"getting-started/#initial-configuration","title":"Initial Configuration","text":"<p>InfluencerPy uses a configuration wizard to make setup easy. You don't need to manually edit config files unless you want to.</p>"},{"location":"getting-started/#1-run-the-cli","title":"1. Run the CLI","text":"<p>Start the application:</p> <pre><code>influencerpy\n</code></pre>"},{"location":"getting-started/#2-setup-credentials","title":"2. Setup Credentials","text":"<p>On your first run, you will see the Credential Setup Guide.</p> <ol> <li>The wizard will ask for your Gemini API Key (required for AI features).</li> <li>It will ask for your Telegram Bot Token and Chat ID (required for receiving reports).</li> <li>Optionally, add X API credentials if you plan to post to Twitter.</li> <li>These are saved securely in a <code>.env</code> file in your project root.</li> </ol>"},{"location":"getting-started/#3-configure-ai-settings","title":"3. Configure AI Settings","text":"<p>By default, InfluencerPy uses Gemini Flash for fast processing. You can customize this:</p> <ol> <li>Select Configure AI Settings from the main menu.</li> <li>Choose your provider: Gemini or Anthropic.</li> <li>Set a specific Model ID (e.g., <code>gemini-2.5-flash</code> for speed, or <code>claude-sonnet-4</code> for quality).</li> <li>Adjust the Temperature (default <code>0.7</code>). Higher values make output more creative; lower values make it more factual.</li> </ol>"},{"location":"getting-started/#4-optional-telemetry-langfuse","title":"4. Optional: Telemetry (Langfuse)","text":"<p>To trace and debug your Scout's AI reasoning, you can enable Langfuse integration.</p> <ol> <li>Select Configure AI Settings -&gt; Langfuse (Tracing) from the menu.</li> <li>Enter your Host, Public Key, and Secret Key.</li> <li>This setting is global: once enabled, all Scouts will report traces to your Langfuse project.</li> </ol>"},{"location":"getting-started/#creating-your-first-scout","title":"Creating Your First Scout","text":"<p>Let's create a content discovery scout:</p> <ol> <li>Run <code>influencerpy</code> and select \"Scouts\" \u2192 \"Create Scout\"</li> <li>Choose Intent: Select \"\ud83d\udd0d Content Discovery\" (this finds and lists content)</li> <li>Scout Type: Choose a source (RSS, Reddit, Arxiv, etc.)</li> <li>Configure Source: Enter feed URLs, subreddits, or search queries</li> <li>Tip: For RSS feeds, you can add multiple feeds separated by commas (e.g., <code>https://feed1.com/rss, https://feed2.com/rss</code>)</li> <li>Schedule: Set when it should run (Daily, Weekly, or Manual)</li> <li>Done!: Your scout is ready</li> </ol>"},{"location":"getting-started/#running-your-scout","title":"Running Your Scout","text":"<p>Manual Run: - From CLI: Select the scout and choose \"Run Scout\" - From Telegram: Send <code>/scouts</code> and click \"\ud83d\ude80 Run Scout\"</p> <p>Scheduled Run: - The bot will automatically run scouts based on their schedule - Reports are sent to Telegram</p>"},{"location":"getting-started/#what-youll-receive","title":"What You'll Receive","text":"<p>For Scouting Intent scouts, you'll receive: - A curated list of content items - Summary of each item - Links to original sources - Delivered via Telegram for easy reading</p> <p>For Generation Intent scouts (optional), you'll receive: - Draft social media posts - Ready to post to X (Twitter) or copy/paste elsewhere</p>"},{"location":"getting-started/#example-multi-feed-ai-research-scout","title":"Example: Multi-Feed AI Research Scout","text":"<p>Here's a complete example of creating a content discovery scout that monitors multiple AI research sources:</p>"},{"location":"getting-started/#configuration","title":"Configuration","text":"<pre><code>Scout Name: AI Research Digest\nIntent: \ud83d\udd0d Content Discovery (Scouting)\nScout Type: \ud83d\udce1 RSS\nRSS Feed URLs: https://tldr.takara.ai/api/papers, https://bair.berkeley.edu/blog/feed.xml, https://research.google/blog/rss/, https://news.mit.edu/rss/topic/artificial-intelligence2, https://news.microsoft.com/source/topics/ai/feed/\nSchedule: Daily at 9:00 AM\n</code></pre>"},{"location":"getting-started/#what-this-does","title":"What This Does","text":"<p>This scout will:</p> <ol> <li>Monitor 5 AI research sources simultaneously:</li> <li>Takara AI TLDR Papers</li> <li>Berkeley AI Research (BAIR) Blog</li> <li>Google Research Blog</li> <li>MIT AI News</li> <li> <p>Microsoft AI News</p> </li> <li> <p>Explore ALL feeds comprehensively: The AI automatically reads entries from ALL 5 feeds (not just one), gathering diverse content across all sources</p> </li> <li> <p>Analyze and select the best content: The AI reviews articles from all feeds and selects the most relevant and interesting ones</p> </li> <li> <p>Deliver a curated report to Telegram with:</p> </li> <li>Article titles and summaries</li> <li>Key insights from each piece</li> <li>Links to original sources</li> <li>Source attribution (showing which feed each article came from)</li> <li>Delivered every morning at 9 AM</li> </ol>"},{"location":"getting-started/#sample-output","title":"Sample Output","text":"<pre><code># \ud83d\udcda AI Research Digest - Content Discovery\n*Found 6 interesting items from 5 sources*\n\n## 1. New Advances in Multimodal Learning\nSummary: Researchers at Berkeley demonstrate significant improvements in vision-language models...\n\ud83d\udd17 Source: https://bair.berkeley.edu/blog/2025/...\n\n## 2. Scaling Language Models: Latest Insights\nSummary: Google Research shares findings on training efficiency...\n\ud83d\udd17 Source: https://research.google/blog/...\n\n[... more items ...]\n</code></pre>"},{"location":"getting-started/#why-multiple-feeds","title":"Why Multiple Feeds?","text":"<ul> <li>Broader coverage: Get diverse perspectives from academia and industry</li> <li>All feeds explored: The agent automatically reads from ALL feeds, not just one</li> <li>Better selection: More content from multiple sources means the AI can pick truly standout articles</li> <li>Single digest: One consolidated report instead of multiple notifications</li> <li>Source attribution: See which feed each article came from</li> <li>Efficient: Set up once, runs automatically every day</li> </ul>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>\ud83d\udc49 Learn about Scouts to understand scouting vs generation</li> <li>\ud83d\udc49 Explore Scheduling to automate your scouts</li> <li>\ud83d\udc49 Telegram Integration for remote management</li> </ul>"},{"location":"reference/","title":"API Reference","text":"<p>Coming soon.</p>"},{"location":"channels/telegram/","title":"Telegram Integration","text":"<p>InfluencerPy includes a powerful Telegram integration that allows you to monitor your scouts, review drafts, and trigger runs remotely.</p>"},{"location":"channels/telegram/#setup","title":"Setup","text":"<p>To use the Telegram features, you need to create a Telegram Bot and configure InfluencerPy with your credentials.</p>"},{"location":"channels/telegram/#1-create-a-telegram-bot","title":"1. Create a Telegram Bot","text":"<ol> <li>Open Telegram and search for @BotFather.</li> <li>Send the command <code>/newbot</code>.</li> <li>Follow the prompts to name your bot (e.g., \"MyInfluencerBot\").</li> <li>Copy the HTTP API Token provided by BotFather.</li> </ol>"},{"location":"channels/telegram/#2-get-your-chat-id","title":"2. Get Your Chat ID","text":"<ol> <li>Search for @userinfobot on Telegram.</li> <li>Start the chat.</li> <li>Copy the \"Id\" (a number) it sends you.</li> </ol>"},{"location":"channels/telegram/#3-configure-influencerpy","title":"3. Configure InfluencerPy","text":"<p>Run the configuration wizard: <pre><code>influencerpy configure\n</code></pre> Select Telegram and enter your Bot Token and Chat ID.</p>"},{"location":"channels/telegram/#running-the-bot","title":"Running the Bot","text":"<p>To start the Telegram listener, run:</p> <pre><code>influencerpy bot\n</code></pre> <p>Keep this command running (e.g., in a background terminal or on a server). The bot will poll for updates and handle notifications.</p>"},{"location":"channels/telegram/#features","title":"Features","text":""},{"location":"channels/telegram/#review-notifications","title":"\ud83d\udd14 Review Notifications","text":"<p>When a Scout generates a draft (and <code>telegram_review</code> is enabled), the bot will send you a message with the draft content and inline buttons:</p> <ul> <li>\u2705 Confirm: <ul> <li>For X/Twitter: Posts the content immediately</li> <li>For Telegram-only drafts (e.g., Substack content): Marks as confirmed - you can then manually copy/paste the content to your target platform</li> </ul> </li> <li>\u274c Reject: Discards the draft.</li> <li>\ud83d\udcac Feedback/Edit: Provide feedback to regenerate the draft with your improvements.</li> </ul>"},{"location":"channels/telegram/#platform-specific-workflows","title":"Platform-Specific Workflows","text":""},{"location":"channels/telegram/#x-twitter-posts","title":"X (Twitter) Posts","text":"<p>When you click \u2705 Confirm, the content is automatically posted to X/Twitter.</p>"},{"location":"channels/telegram/#telegram-only-posts-eg-substack","title":"Telegram-Only Posts (e.g., Substack)","text":"<p>For platforms that don't support automated posting: 1. Scout generates a draft and sends it to Telegram 2. Review the content 3. Click \u2705 Confirm to acknowledge 4. Manually copy the content from Telegram 5. Paste and publish on your target platform (e.g., Substack)</p> <p>This workflow is useful for platforms like Substack where API posting isn't supported or when you want full manual control.</p>"},{"location":"channels/telegram/#manage-scouts-scouts","title":"\ud83d\udd75\ufe0f Manage Scouts (<code>/scouts</code>)","text":"<p>You can list and run your configured scouts directly from Telegram.</p> <ol> <li>Send the command <code>/scouts</code>.</li> <li>The bot will list your available scouts.</li> <li>Click \ud83d\ude80 Run Scout next to any scout to trigger it immediately.<ul> <li>The scout will run in the background.</li> <li>Once finished, the bot will send you the generated draft for review.</li> </ul> </li> </ol>"},{"location":"channels/telegram/#manual-check-check","title":"\ud83d\udd04 Manual Check (<code>/check</code>)","text":"<p>If you think you missed a notification or want to force a check for pending drafts in the database:</p> <ol> <li>Send the command <code>/check</code>.</li> <li>The bot will query the database for any posts with <code>pending_review</code> status and send them to you.</li> </ol>"},{"location":"concepts/image-generation/","title":"Image Generation","text":"<p>InfluencerPy integrates with Stability AI to automatically generate high-quality images for your social media posts.</p>"},{"location":"concepts/image-generation/#features","title":"Features","text":"<ul> <li>Context-Aware: The AI analyzes the content found by your Scout and generates a relevant image prompt.</li> <li>High Quality: Uses Stability AI's latest models (e.g., Stable Image Core) for professional results.</li> <li>Automated: Images are generated and attached to your draft posts automatically.</li> </ul>"},{"location":"concepts/image-generation/#setup","title":"Setup","text":"<ol> <li>Get an API Key: Sign up at Stability AI Platform and generate an API Key.</li> <li>Configure InfluencerPy:     <pre><code>influencerpy configure\n</code></pre>     Select \"Stability AI\" and paste your key.</li> </ol>"},{"location":"concepts/image-generation/#usage","title":"Usage","text":"<p>When creating a new Scout, you will be asked:</p> <p>Enable Image Generation (requires Stability AI)?</p> <p>Select Yes.</p> <p>Now, whenever this Scout runs: 1.  It finds interesting content (e.g., a news article). 2.  It generates a text draft. 3.  It calls Stability AI to generate an image representing that content. 4.  The image is saved locally and referenced in your draft.</p>"},{"location":"concepts/image-generation/#cost","title":"Cost","text":"<p>Image generation uses credits from your Stability AI account. Please refer to their pricing page for current rates.</p>"},{"location":"concepts/scheduler/","title":"Scout Scheduler","text":"<p>The Scout Scheduler is the heartbeat of InfluencerPy's automation. It ensures your scouts run automatically at their configured times, fetching content and generating drafts even when you're away.</p>"},{"location":"concepts/scheduler/#how-it-works","title":"How it Works","text":"<p>The scheduler is built on top of <code>APScheduler</code> and runs alongside the Telegram bot when you execute:</p> <pre><code>influencerpy bot\n</code></pre> <p>It loads all your Scouts from the database and schedules them based on their Cron expressions.</p>"},{"location":"concepts/scheduler/#configuration","title":"Configuration","text":"<p>When creating or updating a Scout, you can choose from several scheduling options:</p> <ul> <li>Daily: Runs every day at a specific time (e.g., 09:00 AM).</li> <li>Hourly: Runs at the top of every hour.</li> <li>Weekly: Runs on specific days of the week.</li> <li>Interval: Runs every X hours.</li> <li>Custom Cron: For advanced users, you can provide a standard Cron expression (e.g., <code>0 12 * * 1-5</code> for weekdays at noon).</li> </ul>"},{"location":"concepts/scheduler/#monitoring","title":"Monitoring","text":"<p>You can monitor the scheduler's activity using the logs command:</p> <pre><code>influencerpy logs -f\n</code></pre> <p>You will see messages like: <pre><code>INFO - Scheduled scout 'Daily AI' with cron: 0 9 * * *\nINFO - Executing scheduled run for scout: Daily AI\nINFO - Generated and saved draft for Daily AI: Top 10 AI Trends\n</code></pre></p>"},{"location":"concepts/scheduler/#review-workflow","title":"Review Workflow","text":"<p>When a scheduled scout finds content: 1.  It generates a draft post using your configured AI model. 2.  It saves the draft to the database with a status of <code>pending_review</code>. 3.  The Telegram Bot detects the new draft and sends you a notification with \"Approve\" and \"Reject\" buttons.</p>"},{"location":"concepts/scheduling/","title":"Scheduling","text":"<p>InfluencerPy includes a powerful Schedule Builder to help you plan when your Scouts should run.</p>"},{"location":"concepts/scheduling/#configuration","title":"Configuration","text":"<p>When creating or updating a Scout, you can assign a schedule using the interactive wizard.</p>"},{"location":"concepts/scheduling/#the-schedule-builder","title":"The Schedule Builder","text":"<p>You don't need to know complex cron syntax. The CLI offers an easy-to-use menu:</p> <ol> <li>Daily: Select specific hours (e.g., <code>09:00</code>, <code>18:00</code>).</li> <li>Weekly: Select specific days and time (e.g., <code>Monday</code> and <code>Friday</code> at <code>10:00</code>).</li> <li>Monthly: Run on a specific day of the month.</li> <li>Interval: Run every X hours.</li> <li>Advanced: Manually enter a cron string (e.g., <code>0 12 * * 1</code>).</li> </ol>"},{"location":"concepts/scheduling/#execution","title":"Execution","text":"<p>Currently, the schedule configuration is stored as metadata attached to your Scout.</p> <p>Note: The background daemon that automatically executes Scouts based on this schedule is currently in development.</p>"},{"location":"concepts/scheduling/#recommended-workflow-current","title":"Recommended Workflow (Current)","text":"<p>For now, we recommend running your Scouts manually via the CLI when you are ready to review content:</p> <pre><code>influencerpy\n# Select \"Manage Scouts\" -&gt; \"Run Scout\"\n</code></pre> <p>Or, for automation experts, you can use your system's <code>cron</code> or <code>launchd</code> to trigger the CLI command (feature coming soon: <code>influencerpy run scout-name</code>).</p>"},{"location":"concepts/scouts/","title":"Scouts","text":"<p>Scouts are the autonomous agents at the heart of InfluencerPy. Think of them as tireless research assistants that constantly monitor the web for content that matches your specific interests and deliver curated reports or generate social media posts based on their intent.</p>"},{"location":"concepts/scouts/#scout-intents","title":"Scout Intents","text":"<p>Every scout has an intent that determines how it processes and delivers content:</p>"},{"location":"concepts/scouts/#scouting-intent-primary-use-case","title":"\ud83d\udd0d Scouting Intent (Primary Use Case)","text":"<p>Goal: Find and list interesting content with summaries and links</p> <p>Perfect for: - Research and staying informed in your field - Competitive intelligence - Content curation for newsletters - Discovery and learning</p> <p>Output: A formatted report with: - Content titles and summaries - Links to original sources - Delivered via Telegram for easy reading</p> <p>Example Report: <pre><code># \ud83d\udcda Daily AI Papers - Content Discovery\n\n*Found 5 interesting items*\n\n## 1. Large Language Models as Optimizers\nResearchers propose using LLMs to optimize prompts automatically...\n\ud83d\udd17 Source: https://arxiv.org/abs/2309.03409\n\n## 2. Constitutional AI: Harmlessness from AI Feedback  \nAnthropic introduces a method for training safer AI systems...\n\ud83d\udd17 Source: https://arxiv.org/abs/2212.08073\n</code></pre></p>"},{"location":"concepts/scouts/#generation-intent-optional","title":"\u270d\ufe0f Generation Intent (Optional)","text":"<p>Goal: Create social media posts from discovered content</p> <p>Perfect for: - Maintaining active social presence - Content repurposing - Automated Twitter accounts</p> <p>Output: Draft social media posts ready to: - Post automatically to X (Twitter) - Review and edit in Telegram - Copy/paste to other platforms</p> <p>Example Post: <pre><code>\ud83e\udd16 Breakthrough in AI optimization: \n\nNew research shows LLMs can optimize their own prompts,\nimproving performance by up to 50% without human intervention.\n\nThis changes everything for prompt engineering.\n\n\ud83d\udcc4 Read: https://arxiv.org/abs/2309.03409\n</code></pre></p>"},{"location":"concepts/scouts/#the-scout-lifecycle","title":"The Scout Lifecycle","text":"<p>The processing pipeline differs based on intent:</p>"},{"location":"concepts/scouts/#for-scouting-intent","title":"For Scouting Intent:","text":"<ol> <li>Initialization: Scout spins up an AI Agent with specific tools</li> <li>Discovery: Agent searches for content matching the goal</li> <li>AI Selection: Multiple items are analyzed and ranked</li> <li>Formatting: Best items are formatted as a curated list with summaries</li> <li>Delivery: Report sent to Telegram</li> </ol>"},{"location":"concepts/scouts/#for-generation-intent","title":"For Generation Intent:","text":"<ol> <li>Initialization: Scout spins up an AI Agent with specific tools</li> <li>Discovery: Agent searches for content matching the goal</li> <li>AI Selection: Single best item is selected using relevance scoring</li> <li>Drafting: AI generates a social media post tailored to platform and tone</li> <li>Action: Post sent to Telegram for review or directly to platform</li> </ol>"},{"location":"concepts/scouts/#scout-types","title":"Scout Types","text":"<p>InfluencerPy offers multiple specialized Scout types, each designed for different content sources.</p>"},{"location":"concepts/scouts/#1-search-scout","title":"1. Search Scout \ud83d\udd0d","text":"<p>Best for: Discovering new, trending, or broad information</p> <ul> <li>How it works: Uses Google Search (via Gemini Grounding) to perform live web searches</li> <li>Configuration:<ul> <li>Query: Keywords or phrase to search for (e.g., \"Latest AI breakthroughs\")</li> </ul> </li> <li>Example Use Cases:<ul> <li>Scouting: Get daily list of new AI regulation articles with summaries</li> <li>Generation: Create tweets about trending tech news</li> </ul> </li> </ul>"},{"location":"concepts/scouts/#2-rss-scout","title":"2. RSS Scout \ud83d\udce1","text":"<p>Best for: Monitoring specific, trusted sources like blogs and newsletters</p> <ul> <li>How it works: Uses the InfluencerPy RSS Tool to subscribe to XML/Atom feeds</li> <li>Database Storage: Feeds stored locally, preventing duplicate content</li> <li>Multi-Feed Support: When multiple feeds are subscribed, the agent explores ALL of them and gathers entries from each source</li> <li>Configuration:<ul> <li>Feeds: List of RSS Feed URLs (validated automatically)</li> <li>Tip: You can add multiple feeds at once by separating them with commas (e.g., <code>https://feed1.com/rss, https://feed2.com/rss</code>)</li> </ul> </li> <li>Intelligence: Agent analyzes feed entries across all sources for relevance, presenting diverse perspectives</li> <li>Example Use Cases:<ul> <li>Scouting: Weekly digest combining TechCrunch, Ars Technica, and The Verge with summaries</li> <li>Generation: Daily tweets about blog posts from favorite sources</li> </ul> </li> </ul>"},{"location":"concepts/scouts/#3-substack-scout","title":"3. Substack Scout \ud83d\udcf0","text":"<p>Best for: Monitoring Substack newsletters and accessing paywalled content</p> <ul> <li>How it works: Uses the Substack API to fetch posts</li> <li>Configuration:<ul> <li>Newsletter URL: Substack publication to monitor</li> <li>Sorting: \"new\" (most recent) or \"top\" (most popular)</li> </ul> </li> <li>Authentication: Optional cookies for paywalled content</li> <li>Example Use Cases:<ul> <li>Scouting: Track industry newsletters and get summaries with links</li> <li>Generation: Share insights from newsletters as Twitter threads</li> </ul> </li> <li>Setup: See Substack Platform Guide</li> </ul>"},{"location":"concepts/scouts/#4-reddit-scout","title":"4. Reddit Scout \ud83d\udc7e","text":"<p>Best for: Community discussions, viral trends, and niche opinions</p> <ul> <li>How it works: Fetches \"Hot\" posts from subreddits</li> <li>Configuration:<ul> <li>Subreddits: List of subreddit names (without <code>r/</code>)</li> </ul> </li> <li>Example Use Cases:<ul> <li>Scouting: Daily list of trending discussions in r/MachineLearning</li> <li>Generation: Tweets about viral Reddit posts with community sentiment</li> </ul> </li> </ul>"},{"location":"concepts/scouts/#5-arxiv-scout","title":"5. Arxiv Scout \ud83c\udf93","text":"<p>Best for: Academic papers and technical research</p> <ul> <li>How it works: Searches Arxiv.org database</li> <li>Configuration:<ul> <li>Query: Search topic or Arxiv ID</li> <li>Date Filter: \"Today\", \"This Week\", or \"This Month\"</li> </ul> </li> <li>Example Use Cases:<ul> <li>Scouting: Weekly roundup of new LLM papers with abstracts</li> <li>Generation: Thread explaining breakthrough research papers</li> </ul> </li> </ul>"},{"location":"concepts/scouts/#6-http-request-scout","title":"6. HTTP Request Scout \ud83c\udf10","text":"<p>Best for: Monitoring specific webpages or analyzing static resources</p> <ul> <li>How it works: Fetches raw HTML/Text from URLs</li> <li>Configuration:<ul> <li>URL: Target website address</li> </ul> </li> <li>Example Use Cases:<ul> <li>Scouting: Monitor company press release pages for updates</li> <li>Generation: Posts about new product announcements</li> </ul> </li> </ul>"},{"location":"concepts/scouts/#7-meta-scout-orchestrator","title":"7. Meta-Scout (Orchestrator) \ud83e\udd16","text":"<p>Best for: Complex research combining multiple sources</p> <ul> <li>How it works: Orchestrates multiple scouts or tools</li> <li>Configuration:<ul> <li>Tools: Enabled capabilities (Search, Arxiv, HTTP, etc.)</li> <li>Goal: High-level instruction for tool coordination</li> </ul> </li> <li>Example Use Cases:<ul> <li>Scouting: Comprehensive reports combining news, papers, and discussions</li> <li>Generation: Multi-perspective posts synthesizing various sources</li> </ul> </li> </ul>"},{"location":"concepts/scouts/#optimization-calibration","title":"Optimization &amp; Calibration","text":"<p>Scouts improve over time through feedback:</p>"},{"location":"concepts/scouts/#the-calibration-loop","title":"The Calibration Loop","text":"<ol> <li>Run <code>influencerpy</code> \u2192 Manage Scouts \u2192 Calibrate Scout</li> <li>Scout generates output (list or post depending on intent)</li> <li>Provide Feedback (e.g., \"Too technical\" or \"Include more context\")</li> <li>Meta-Prompting: AI rewrites the Scout's system prompt automatically</li> <li>Future outputs reflect your preferences</li> </ol>"},{"location":"concepts/scouts/#feedback-recording","title":"Feedback Recording","text":"<p>When reviewing scouts: *   Rejecting content prompts for a reason *   Feedback stored in database *   Used to optimize selection logic and search queries</p>"},{"location":"concepts/scouts/#choosing-the-right-intent","title":"Choosing the Right Intent","text":"<p>Use Scouting Intent when you want to: - \u2705 Stay informed without publishing - \u2705 Research and learn - \u2705 Curate content for others (newsletters, teams) - \u2705 Monitor competitors or trends - \u2705 Keep links to original sources</p> <p>Use Generation Intent when you want to: - \u2705 Maintain active social media presence - \u2705 Automate content posting - \u2705 Repurpose content for different platforms - \u2705 Save time on social media management</p> <p>You can mix both! Create scouting scouts for research and generation scouts for posting.</p>"},{"location":"concepts/system-prompts/","title":"System Prompts Architecture","text":""},{"location":"concepts/system-prompts/#overview","title":"Overview","text":"<p>InfluencerPy uses a structured system prompt architecture that separates concerns into four distinct components. This ensures users can customize their scout's behavior without accidentally breaking system guardrails or platform formatting rules.</p>"},{"location":"concepts/system-prompts/#prompt-components","title":"Prompt Components","text":""},{"location":"concepts/system-prompts/#1-general-instructions-hidden","title":"1. General Instructions (Hidden)","text":"<p>Purpose: Core system guardrails and professional behavioral guidelines.</p> <p>Content: - Be objective and fact-based - Prioritize quality over quantity - Respect copyright and attribution - Avoid clickbait or sensationalism</p> <p>Visibility: Hidden from users, automatically included in all scouts.</p>"},{"location":"concepts/system-prompts/#2-tool-instructions-hidden","title":"2. Tool Instructions (Hidden)","text":"<p>Purpose: Auto-generated guidance for using enabled tools.</p> <p>Content: Varies based on scout type and tools: - google_search: How to formulate search queries - rss: How to parse feed items - reddit: How to browse subreddit discussions - arxiv: How to search academic papers - browser [EXPERIMENTAL]: How to navigate and extract content</p> <p>Visibility: Hidden from users, automatically generated based on configured tools.</p>"},{"location":"concepts/system-prompts/#3-platform-instructions-hidden","title":"3. Platform Instructions (Hidden)","text":"<p>Purpose: Platform-specific formatting and constraints.</p> <p>Supported Platforms:</p> <p>X (Twitter): - Maximum 280 characters per post - 2-3 hashtags maximum - Emojis for engagement - Threading for longer content</p> <p>LinkedIn: - Professional tone - Up to 3000 characters - Focus on insights and takeaways - Strategic use of line breaks</p> <p>Visibility: Hidden from users, automatically applied based on target platform.</p>"},{"location":"concepts/system-prompts/#4-user-instructions-visible-editable","title":"4. User Instructions (Visible &amp; Editable)","text":"<p>Purpose: Your custom scout goal.</p> <p>Examples: - \"Find breaking AI safety research\" - \"Summarize this content for a technical audience\" - \"Find controversial blockchain discussions\"</p> <p>Visibility: This is the ONLY component users see and edit in the UI.</p> <p>Label in UI: \"User Instructions (Your Scout Goal)\"</p>"},{"location":"concepts/system-prompts/#how-it-works","title":"How It Works","text":""},{"location":"concepts/system-prompts/#prompt-construction","title":"Prompt Construction","text":"<p>When a scout runs, the system builds the final prompt using the <code>SystemPrompt</code> dataclass:</p> <pre><code>from influencerpy.core.prompts import SystemPrompt\nfrom influencerpy.types.prompts import (\n    GENERAL_GUARDRAILS,\n    build_tool_prompt,\n    get_platform_instructions\n)\n\nsystem_prompt = SystemPrompt(\n    general_instructions=GENERAL_GUARDRAILS,\n    tool_instructions=build_tool_prompt([\"rss\", \"google_search\"]),\n    platform_instructions=get_platform_instructions(\"x\"),\n    user_instructions=\"Find trending AI news\"\n)\n\nfinal_prompt = system_prompt.build(\n    date=\"2025-11-28\",\n    limit=10\n)\n</code></pre>"},{"location":"concepts/system-prompts/#example-output","title":"Example Output","text":"<p>The final prompt sent to the AI looks like:</p> <pre><code>You are a professional content scout and curator for social media.\n\nCORE PRINCIPLES:\n- Be objective and fact-based in your analysis\n- Prioritize quality over quantity\n- Respect copyright and provide proper attribution\n- Avoid clickbait or sensationalism\n\nAVAILABLE TOOLS:\n\nTOOL: rss\nUse this to fetch feed items from the configured RSS source.\n\nTOOL: google_search\nUse this to find recent news, articles, and web content.\n\nYOUR GOAL: Find trending AI news\n\nOUTPUT FORMAT FOR X (TWITTER):\n- Maximum 280 characters per post\n- Use 2-3 relevant hashtags maximum\n- Include emojis strategically for engagement\n\nCONTEXT:\ndate: 2025-11-28\nlimit: 10\n</code></pre>"},{"location":"concepts/system-prompts/#benefits","title":"Benefits","text":""},{"location":"concepts/system-prompts/#for-users","title":"For Users","text":"<p>\u2705 Simple UX: Only edit your custom goal, not system internals \u2705 Protected: Can't accidentally break guardrails or formatting \u2705 Platform-Aware: Posts automatically formatted correctly \u2705 Tool-Aware: Instructions auto-update when tools change</p>"},{"location":"concepts/system-prompts/#for-developers","title":"For Developers","text":"<p>\u2705 Maintainable: All prompt logic centralized \u2705 Testable: Each component independently verifiable \u2705 Extensible: Easy to add new platforms or tools \u2705 Type-Safe: Dataclass ensures valid composition</p>"},{"location":"concepts/system-prompts/#customization","title":"Customization","text":""},{"location":"concepts/system-prompts/#editing-user-instructions","title":"Editing User Instructions","text":"<ol> <li>In the CLI, select Update Scout</li> <li>Choose User Instructions</li> <li>Enter your custom goal</li> </ol> <p>Your instruction will be combined with system guardrails, tool guidance, and platform formatting automatically.</p>"},{"location":"concepts/system-prompts/#adding-new-platforms","title":"Adding New Platforms","text":"<p>To add a new platform (e.g., Instagram):</p> <ol> <li>Edit <code>src/influencerpy.types.prompts.py</code></li> <li> <p>Add to <code>PLATFORM_INSTRUCTIONS</code> dictionary:    <pre><code>\"instagram\": \"\"\"OUTPUT FORMAT FOR INSTAGRAM:\n- Visually-driven content\n- Up to 2200 characters\n- Use emojis liberally\n- Hashtags at the end (up to 30)\"\"\"\n</code></pre></p> </li> <li> <p>No other code changes needed!</p> </li> </ol>"},{"location":"concepts/system-prompts/#migration","title":"Migration","text":"<p>Existing scouts are fully backward compatible. The <code>prompt_template</code> field is now interpreted as \"User Instructions\" and combined with system components automatically.</p>"},{"location":"concepts/tools/","title":"Available Tools","text":"<p>InfluencerPy agents have access to several powerful tools for content discovery and analysis. Each tool serves a specific purpose and can be combined to create sophisticated content workflows.</p>"},{"location":"concepts/tools/#core-tools","title":"Core Tools","text":""},{"location":"concepts/tools/#1-http-request-tool","title":"1. HTTP Request Tool \ud83c\udf10","text":"<p>Purpose: Fetch and parse content from any web URL using Beautiful Soup.</p> <p>Best for: - Reading blog posts and articles - Extracting specific content using CSS selectors - Monitoring webpage content - Getting links from pages</p> <p>Usage: <pre><code>http_request(\n    url=\"https://example.com/article\",\n    selector=\"article\",  # Optional: CSS selector\n    extract_links=True   # Optional: Extract all links\n)\n</code></pre></p> <p>Features: - Clean text extraction (removes scripts, styles) - CSS selector support for targeting specific elements - Link extraction with absolute URLs - Automatic content truncation (10,000 char limit) - 10-second timeout for reliability - Graceful error handling</p> <p>Example Configuration: <pre><code>scout = manager.create_scout(\n    name=\"Blog Monitor\",\n    type=\"meta\",\n    config={\n        \"tools\": [\"http_request\"],\n        \"orchestration_prompt\": \"Monitor tech blogs for interesting articles\"\n    }\n)\n</code></pre></p> <p>See: HTTP Request Tool Documentation</p>"},{"location":"concepts/tools/#2-google-search-tool","title":"2. Google Search Tool \ud83d\udd0d","text":"<p>Purpose: Perform real-time web searches using Gemini Grounding.</p> <p>Best for: - Finding recent news and updates - Discovering trending topics - General web research</p> <p>Usage: <pre><code>google_search(query=\"machine learning breakthroughs 2026\")\n</code></pre></p> <p>Features: - Real-time search results - Automatic source attribution - Grounded responses with citations - Detailed summaries (3-4 paragraphs)</p> <p>Example Configuration: <pre><code>scout = manager.create_scout(\n    name=\"News Scout\",\n    type=\"search\",\n    config={\n        \"tools\": [\"google_search\"],\n        \"query\": \"AI regulation news\"\n    }\n)\n</code></pre></p>"},{"location":"concepts/tools/#3-rss-tool","title":"3. RSS Tool \ud83d\udce1","text":"<p>Purpose: Subscribe to and manage RSS/Atom feeds.</p> <p>Best for: - Monitoring specific blogs and news sites - Following trusted content sources - Tracking updates from known publishers</p> <p>Usage: <pre><code># List feeds\nrss(action=\"list\")\n\n# Read feed\nrss(action=\"read\", feed_id=\"feed_123\")\n\n# Add feed\nrss(action=\"add\", url=\"https://blog.example.com/feed\")\n</code></pre></p> <p>Features: - Database-backed feed storage - Automatic feed validation - Duplicate detection - Per-scout feed isolation</p> <p>Example Configuration: <pre><code>scout = manager.create_scout(\n    name=\"Tech Blog Scout\",\n    type=\"rss\",\n    config={\n        \"tools\": [\"rss\"],\n        \"feeds\": [\"https://techcrunch.com/feed/\"]\n    }\n)\n</code></pre></p>"},{"location":"concepts/tools/#4-reddit-tool","title":"4. Reddit Tool \ud83d\udc7e","text":"<p>Purpose: Fetch posts from subreddits.</p> <p>Best for: - Community sentiment analysis - Finding trending discussions - Tapping into niche communities</p> <p>Usage: <pre><code>reddit(\n    subreddit=\"MachineLearning\",\n    limit=10,\n    sort=\"hot\"  # or \"new\", \"top\", \"rising\"\n)\n</code></pre></p> <p>Features: - Multiple sorting options (hot, new, top, rising) - Configurable post limits - Upvote and comment counts - Rate limit compliance</p> <p>Example Configuration: <pre><code>scout = manager.create_scout(\n    name=\"AI Reddit Scout\",\n    type=\"reddit\",\n    config={\n        \"tools\": [\"reddit\"],\n        \"subreddits\": [\"MachineLearning\", \"LocalLLaMA\"],\n        \"reddit_sort\": \"hot\"\n    }\n)\n</code></pre></p>"},{"location":"concepts/tools/#5-arxiv-tool","title":"5. ArXiv Tool \ud83c\udf93","text":"<p>Purpose: Search for academic papers and research.</p> <p>Best for: - Finding research papers - Tracking scientific breakthroughs - Academic content curation</p> <p>Usage: <pre><code>arxiv_search(\n    query=\"transformer models\",\n    days_back=7  # Optional: filter by recency\n)\n</code></pre></p> <p>Features: - Search by keywords or ArXiv ID - Date filtering (days_back parameter) - Full paper metadata (title, authors, abstract) - Direct ArXiv links</p> <p>Example Configuration: <pre><code>scout = manager.create_scout(\n    name=\"AI Papers\",\n    type=\"meta\",\n    config={\n        \"tools\": [\"arxiv\"],\n        \"query\": \"large language models\",\n        \"date_filter\": \"week\"\n    }\n)\n</code></pre></p>"},{"location":"concepts/tools/#6-browser-tool-experimental","title":"6. Browser Tool (Experimental) \ud83c\udf10","text":"<p>Purpose: Navigate web pages with JavaScript support.</p> <p>Best for: - Complex web interactions - JavaScript-heavy sites - Multi-step navigation</p> <p>Usage: <pre><code>browser(\n    url=\"https://example.com\",\n    action=\"navigate\"\n)\n</code></pre></p> <p>Features: - Full browser automation - JavaScript execution - Multi-step interactions - Screenshot capabilities</p> <p>Limitations: - Slower than http_request - More resource-intensive - Experimental stability</p> <p>Example Configuration: <pre><code>scout = manager.create_scout(\n    name=\"Complex Site Monitor\",\n    type=\"meta\",\n    config={\n        \"tools\": [\"browser\"],\n        \"orchestration_prompt\": \"Navigate to site and extract data\"\n    }\n)\n</code></pre></p>"},{"location":"concepts/tools/#tool-comparison","title":"Tool Comparison","text":""},{"location":"concepts/tools/#http-request-vs-browser","title":"HTTP Request vs Browser","text":"Feature http_request browser Speed \u26a1 Fast \ud83d\udc0c Slower JavaScript \u274c No \u2705 Yes CSS Selectors \u2705 Yes \u2705 Yes Stability \u2705 Stable \u26a0\ufe0f Experimental Resource Use \u2b07\ufe0f Low \u2b06\ufe0f High Best For Static content Dynamic sites <p>Recommendation: Use <code>http_request</code> for most web scraping tasks. Only use <code>browser</code> when you specifically need JavaScript execution.</p>"},{"location":"concepts/tools/#combining-tools","title":"Combining Tools","text":"<p>The power of InfluencerPy comes from combining multiple tools in a Meta-Scout:</p>"},{"location":"concepts/tools/#example-complete-research-workflow","title":"Example: Complete Research Workflow","text":"<pre><code>scout = manager.create_scout(\n    name=\"Complete Research Agent\",\n    type=\"meta\",\n    config={\n        \"tools\": [\"google_search\", \"http_request\", \"arxiv\"],\n        \"orchestration_prompt\": \"\"\"\n            1. Use google_search to find trending AI topics\n            2. Use http_request to read full articles\n            3. Use arxiv to find related research papers\n            4. Synthesize findings into a comprehensive post\n        \"\"\"\n    }\n)\n</code></pre>"},{"location":"concepts/tools/#example-news-community-sentiment","title":"Example: News + Community Sentiment","text":"<pre><code>scout = manager.create_scout(\n    name=\"News with Sentiment\",\n    type=\"meta\",\n    config={\n        \"tools\": [\"rss\", \"reddit\", \"http_request\"],\n        \"orchestration_prompt\": \"\"\"\n            1. Check RSS feeds for latest tech news\n            2. Use http_request to read full articles\n            3. Check Reddit for community reactions\n            4. Create a post combining news and sentiment\n        \"\"\"\n    }\n)\n</code></pre>"},{"location":"concepts/tools/#adding-tools-to-scouts","title":"Adding Tools to Scouts","text":"<p>When creating a scout, specify tools in the <code>tools</code> array:</p> <pre><code>from influencerpy.core.scouts import ScoutManager\n\nmanager = ScoutManager()\n\nscout = manager.create_scout(\n    name=\"My Scout\",\n    type=\"meta\",\n    config={\n        \"tools\": [\n            \"http_request\",    # Web scraping\n            \"google_search\",   # Search\n            \"arxiv\",          # Research papers\n            \"reddit\"          # Community discussions\n        ],\n        \"orchestration_prompt\": \"Your orchestration instructions here\"\n    }\n)\n</code></pre>"},{"location":"concepts/tools/#best-practices","title":"Best Practices","text":"<ol> <li>Start Simple: Begin with one tool and add more as needed</li> <li>Choose the Right Tool: Use the comparison tables above</li> <li>Combine Strategically: Think about the workflow (search \u2192 fetch \u2192 analyze)</li> <li>Handle Errors: Tools return error information in responses</li> <li>Respect Rate Limits: Don't hammer endpoints repeatedly</li> <li>Use Selectors: When scraping, use CSS selectors for cleaner content</li> </ol>"},{"location":"concepts/tools/#tool-return-formats","title":"Tool Return Formats","text":"<p>All tools return structured data that the AI can understand:</p>"},{"location":"concepts/tools/#http_request","title":"http_request","text":"<pre><code>{\n    \"url\": str,\n    \"title\": str,\n    \"content\": str,\n    \"links\": [{\"text\": str, \"url\": str}],  # Optional\n    \"error\": str  # If failed\n}\n</code></pre>"},{"location":"concepts/tools/#google_search","title":"google_search","text":"<pre><code>str  # Formatted text with sources\n</code></pre>"},{"location":"concepts/tools/#arxiv_search","title":"arxiv_search","text":"<pre><code>str  # Paper details formatted as text\n</code></pre>"},{"location":"concepts/tools/#reddit","title":"reddit","text":"<pre><code>str  # Posts formatted as text with metadata\n</code></pre>"},{"location":"concepts/tools/#next-steps","title":"Next Steps","text":"<ul> <li>Try the Demo: Run <code>python examples/http_tool_demo.py</code> to see the HTTP tool in action</li> <li>Create a Scout: Use the CLI to create a scout with your desired tools</li> <li>Experiment: Try different tool combinations to find what works best</li> </ul> <p>For detailed API documentation of each tool, see the individual tool documentation files in the <code>docs/tools/</code> directory.</p>"},{"location":"experimental/browser-tool-technical/","title":"Browser Tool - Technical Details","text":""},{"location":"experimental/browser-tool-technical/#architecture","title":"Architecture","text":"<p>The Browser tool integration uses: - LocalChromiumBrowser from <code>strands_tools.browser</code> - Playwright for browser automation - PythonAgentTool wrapper to integrate with Strands agent framework</p>"},{"location":"experimental/browser-tool-technical/#how-it-works","title":"How It Works","text":""},{"location":"experimental/browser-tool-technical/#tool-invocation-flow","title":"Tool Invocation Flow","text":"<pre><code>graph TD\n    A[Agent decides to use browser] --&gt; B[Calls browser_wrapper]\n    B --&gt; C[Unpacks tool_use object]\n    C --&gt; D[Extracts tool_args and toolUseId]\n    D --&gt; E[Calls LocalChromiumBrowser.browser with args]\n    E --&gt; F[Returns result dict with status/output/content]\n    F --&gt; G[Agent processes result]</code></pre>"},{"location":"experimental/browser-tool-technical/#wrapper-function","title":"Wrapper Function","text":"<p>The <code>browser_wrapper</code> in <code>scouts.py</code> handles: 1. Argument injection: Ignores <code>agent</code> and <code>event_loop_cycle_id</code> args from Strands 2. Input unpacking: Extracts <code>input</code> from the <code>tool_use</code> object 3. Result formatting: Wraps results in <code>{status, output, content, toolUseId}</code> format</p>"},{"location":"experimental/browser-tool-technical/#action-format","title":"Action Format","text":"<p>Browser actions are specified as:</p> <pre><code>{\n  \"action\": {\n    \"type\": \"action_name\",\n    ...parameters\n  }\n}\n</code></pre> <p>Available action types: - <code>init_session</code>: Create a new browser session - <code>navigate</code>: Go to a URL - <code>click</code>: Click an element (requires <code>selector</code>) - <code>get_text</code>: Extract text from element (requires <code>selector</code>) - <code>get_html</code>: Get HTML content - <code>evaluate</code>: Run JavaScript (requires <code>script</code>) - <code>screenshot</code>: Take a screenshot</p>"},{"location":"experimental/browser-tool-technical/#integration-points","title":"Integration Points","text":""},{"location":"experimental/browser-tool-technical/#file-srcinfluencerpycorescoutspy","title":"File: <code>src/influencerpy/core/scouts.py</code>","text":"<pre><code># Lines 149-194\nif \"browser\" in tools_config:\n    browser = LocalChromiumBrowser()\n\n    def browser_wrapper(browser_input, agent=None, event_loop_cycle_id=None, **kwargs):\n        # Wrapper logic to handle Strands' argument injection\n        ...\n\n    agent_tools.append(PythonAgentTool(\n        tool_name=browser.browser.tool_spec['name'],\n        tool_spec=browser.browser.tool_spec,\n        tool_func=browser_wrapper\n    ))\n</code></pre>"},{"location":"experimental/browser-tool-technical/#file-srcinfluencerpymainpy","title":"File: <code>src/influencerpy/main.py</code>","text":"<p>Browser tool selection in: - Scout creation flow (line ~666) - Scout update flow (line ~788)</p>"},{"location":"experimental/browser-tool-technical/#debugging","title":"Debugging","text":""},{"location":"experimental/browser-tool-technical/#viewing-browser-actions","title":"Viewing Browser Actions","text":"<p>Check scout logs to see which actions were called:</p> <pre><code>grep -E \"(navigate|click|evaluate)\" .influencerpy/logs/scouts/[ScoutName]/[timestamp].log\n</code></pre>"},{"location":"experimental/browser-tool-technical/#common-debug-patterns","title":"Common Debug Patterns","text":"<p>Agent uses basic actions only: <pre><code>tool_use={'action': {'type': 'init_session', ...}}\ntool_use={'action': {'type': 'navigate', ...}}\ntool_use={'action': {'type': 'get_text', 'selector': 'body'}}\n</code></pre></p> <p>Agent successfully uses evaluate: <pre><code>tool_use={'action': {'type': 'evaluate', 'script': '...'}}\n</code></pre></p> <p>Agent clicks on element: <pre><code>tool_use={'action': {'type': 'click', 'selector': '...'}}\n</code></pre></p>"},{"location":"experimental/browser-tool-technical/#testing","title":"Testing","text":"<p>Run verification script: <pre><code>python3 test_huggingface_papers.py\n</code></pre></p> <p>Expected behavior: - \u2705 Navigate to URL - \u2705 Extract text content - \u274c Click on links (currently broken) - \u274c Use evaluate for JS (currently broken)</p>"},{"location":"experimental/browser-tool/","title":"Browser Tool (Experimental)","text":"<p>\u26a0\ufe0f Status: The Browser tool integration is currently EXPERIMENTAL. </p>"},{"location":"experimental/browser-tool/#overview","title":"Overview","text":"<p>The Browser tool uses Playwright-based browser automation via <code>strands_tools</code> to enable scouts to navigate web pages and extract content dynamically. This is more powerful than simple HTTP requests for JavaScript-heavy sites.</p>"},{"location":"experimental/browser-tool/#current-limitations","title":"Current Limitations","text":""},{"location":"experimental/browser-tool/#multi-step-workflows-not-reliable","title":"\ud83d\udd34 Multi-Step Workflows Not Reliable","text":"<p>The AI agent currently struggles with complex, multi-step browser interactions:</p> <ul> <li>\u274c Click Actions: The agent often doesn't click on links even when instructed</li> <li>\u274c Form Filling: Multi-field forms are not reliably completed</li> <li>\u274c Navigation Sequences: \"Navigate \u2192 Find Element \u2192 Click \u2192 Read Content\" workflows often fail</li> <li>\u274c JavaScript Evaluation: The agent rarely uses the <code>evaluate</code> action even when prompted</li> </ul> <p>Why?: The underlying model (gemini-2.5-flash by default) tends to take the shortest path and only uses basic actions like <code>navigate</code> and <code>get_text</code>.</p>"},{"location":"experimental/browser-tool/#what-works","title":"\u2705 What Works","text":"<ul> <li>\u2705 Single Page Navigation: Navigate to a URL and read its content</li> <li>\u2705 Text Extraction: Extract visible text from a page</li> <li>\u2705 Simple Content Scraping: Get HTML from static pages</li> <li>\u2705 Basic Screenshots: Capture page screenshots</li> </ul>"},{"location":"experimental/browser-tool/#recommended-use-cases","title":"Recommended Use Cases","text":""},{"location":"experimental/browser-tool/#good-use-cases","title":"\u2705 Good Use Cases","text":"<ul> <li>Extracting content from a known, stable URL</li> <li>Reading blog posts or article pages</li> <li>Monitoring specific web pages for text changes</li> <li>Simple content aggregation from listings</li> </ul>"},{"location":"experimental/browser-tool/#not-recommended-yet","title":"\u274c Not Recommended (Yet)","text":"<ul> <li>Complex multi-page workflows</li> <li>Dynamic content requiring clicking through UI</li> <li>Sites requiring form interactions</li> <li>Workflows needing JavaScript inspection</li> </ul>"},{"location":"experimental/browser-tool/#example-what-works","title":"Example: What Works","text":"<pre><code># \u2705 This works well\nscout = {\n    \"name\": \"TechCrunchDaily\",\n    \"type\": \"web\",\n    \"url\": \"https://techcrunch.com\",\n    \"tools\": [\"browser\"],\n    \"goal\": \"Extract the titles and summaries of the top 3 articles\"\n}\n</code></pre>"},{"location":"experimental/browser-tool/#example-what-doesnt-work-reliably","title":"Example: What Doesn't Work Reliably","text":"<pre><code># \u274c This often fails\nscout = {\n    \"name\": \"HuggingFaceTop\",\n    \"type\": \"web\",\n    \"url\": \"https://huggingface.co/papers\",\n    \"tools\": [\"browser\"],\n    \"goal\": \"Find paper with most upvotes, click it, and read the abstract\"\n}\n# Problem: Agent won't click on the paper link\n</code></pre>"},{"location":"experimental/browser-tool/#workarounds","title":"Workarounds","text":"<p>If you need complex browser automation:</p> <ol> <li>Use Direct URLs: If you know the exact URL of the content, navigate directly to it</li> <li>Pre-scraping: Use a separate script to find links, then feed URLs to scouts</li> <li>Simplify Goals: Break complex workflows into multiple simpler scouts</li> <li>Alternative Tools: Use RSS, Reddit, or Arxiv scouts when applicable</li> </ol>"},{"location":"experimental/browser-tool/#known-issues","title":"Known Issues","text":"Issue Status Workaround Agent ignores <code>click</code> instructions Open Navigate directly to target URL Agent ignores <code>evaluate</code> for JS inspection Open Use simpler selectors Agent doesn't follow multi-step prompts Open Use single-action goals"},{"location":"experimental/browser-tool/#future-improvements","title":"Future Improvements","text":"<p>We're actively working on: - [ ] Better prompt engineering for multi-step workflows - [ ] Testing with more capable models (GPT-4, Claude) - [ ] Custom high-level browser actions (e.g., <code>click_most_upvoted_paper()</code>) - [ ] Example-based few-shot prompting</p>"},{"location":"experimental/browser-tool/#reporting-issues","title":"Reporting Issues","text":"<p>If you encounter issues with the Browser tool:</p> <ol> <li>Check the scout logs: <code>.influencerpy/logs/scouts/[ScoutName]/</code></li> <li>Look for which browser actions were actually called</li> <li>Note if <code>evaluate</code> or <code>click</code> actions are missing</li> <li>Report to: GitHub Issues</li> </ol>"},{"location":"experimental/browser-tool/#contributing","title":"Contributing","text":"<p>Help us improve the Browser tool! We especially need: - Test cases for working multi-step workflows - Prompt templates that successfully trigger clicking - Model comparisons (which models follow instructions better?)</p>"},{"location":"platforms/substack/","title":"Substack Platform Integration","text":"<p>InfluencerPy provides integration with Substack as a content source, allowing you to monitor newsletters and use them as inspiration for your own content.</p>"},{"location":"platforms/substack/#features","title":"Features","text":""},{"location":"platforms/substack/#as-a-content-source-scout","title":"As a Content Source (Scout)","text":"<ul> <li>Monitor any public Substack newsletter</li> <li>Filter by sorting (new/top posts)</li> <li>Access paywalled content from newsletters you subscribe to</li> <li>Automatic content extraction and summarization</li> <li>Generate content inspired by Substack posts</li> </ul>"},{"location":"platforms/substack/#setup-for-reading-substack-content","title":"Setup for Reading Substack Content","text":""},{"location":"platforms/substack/#optional-authentication-for-paywalled-content","title":"Optional: Authentication for Paywalled Content","text":"<p>If you want to read paywalled content from newsletters you subscribe to, you'll need to provide authentication:</p> <ol> <li>Log into your Substack account in your browser</li> <li>Open Developer Tools (F12)</li> <li>Go to Application/Storage \u2192 Cookies</li> <li>Find and copy these cookies:</li> <li><code>substack.sid</code></li> <li><code>substack.lli</code></li> <li>Add them to your <code>.influencerpy/.env</code> file:</li> </ol> <pre><code>SUBSTACK_SUBDOMAIN=your-subdomain\nSUBSTACK_SID=your_sid_value_here\nSUBSTACK_LLI=your_lli_value_here\n</code></pre> <p>Note: These cookies may expire and need to be refreshed periodically.</p>"},{"location":"platforms/substack/#using-substack-as-a-scout","title":"Using Substack as a Scout","text":"<p>Create a Substack Scout to monitor newsletters:</p> <pre><code>influencerpy scouts\n# Select \"Create Scout\"\n# Choose \"\ud83d\udcf0 Substack (Follow newsletters)\"\n</code></pre>"},{"location":"platforms/substack/#workflow-for-substack-inspired-content","title":"Workflow for Substack-Inspired Content","text":"<ol> <li>Create a scout that monitors Substack newsletters</li> <li>Set platform to \"Telegram\" when configuring output channels</li> <li>Scout runs and generates drafts based on Substack content</li> <li>Review drafts in Telegram - edit if needed</li> <li>Click \u2705 Confirm to mark as ready</li> <li>Manually copy/paste the content to your Substack publication and publish</li> </ol>"},{"location":"platforms/substack/#why-manual-publishing","title":"Why Manual Publishing?","text":"<p>Substack's API doesn't support automated draft creation for security reasons. This manual workflow ensures you have full control over what gets published while still benefiting from automated content discovery and draft generation.</p>"},{"location":"platforms/substack/#example-scout-configuration","title":"Example Scout Configuration","text":"<pre><code>Scout Name: Weekly AI Substack\nType: Substack\nURL: https://example.substack.com\nPlatforms: [\"telegram\"]\nSchedule: Weekly (every Monday)\n</code></pre> <p>When this scout runs: 1. It monitors the specified Substack newsletter 2. Generates a draft based on recent posts 3. Sends the draft to your Telegram for review 4. You copy/paste the approved draft to your own Substack</p>"},{"location":"platforms/substack/#additional-resources","title":"Additional Resources","text":"<ul> <li>Scout Concepts - Understanding scouts</li> <li>Telegram Channel - Setting up Telegram bot</li> <li>Scheduling - Automating scouts</li> </ul>"},{"location":"tools/http-request-technical/","title":"HTTP Request Tool - Technical Overview","text":""},{"location":"tools/http-request-technical/#architecture","title":"Architecture","text":"<p>The HTTP Request tool integrates seamlessly with InfluencerPy's agent system:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         User/CLI                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Scout Manager                            \u2502\n\u2502  - Orchestrates scout execution                             \u2502\n\u2502  - Manages tool configuration                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      AI Agent                               \u2502\n\u2502  - Powered by Gemini/Anthropic                              \u2502\n\u2502  - Equipped with selected tools                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u25bc               \u25bc               \u25bc               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Google    \u2502 \u2502   HTTP      \u2502 \u2502   Reddit    \u2502 \u2502   ArXiv     \u2502\n\u2502   Search    \u2502 \u2502   Request   \u2502 \u2502    Tool     \u2502 \u2502    Tool     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n                       \u25bc\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502   Beautiful Soup     \u2502\n            \u2502   - HTML Parsing     \u2502\n            \u2502   - CSS Selectors    \u2502\n            \u2502   - Text Extraction  \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"tools/http-request-technical/#data-flow","title":"Data Flow","text":""},{"location":"tools/http-request-technical/#1-tool-invocation","title":"1. Tool Invocation","text":"<pre><code># Agent calls the tool\nresult = http_request(\n    url=\"https://example.com/article\",\n    selector=\"article\"\n)\n</code></pre>"},{"location":"tools/http-request-technical/#2-request-processing","title":"2. Request Processing","text":"<pre><code>Request \u2192 Headers \u2192 HTTP GET \u2192 Response \u2192 Parse HTML \u2192 Extract Text \u2192 Clean \u2192 Return\n</code></pre>"},{"location":"tools/http-request-technical/#3-response-handling","title":"3. Response Handling","text":"<pre><code># Agent receives structured data\n{\n    \"url\": \"https://example.com/article\",\n    \"title\": \"Article Title\",\n    \"content\": \"Clean extracted text...\",\n    \"links\": [...]  # If requested\n}\n</code></pre>"},{"location":"tools/http-request-technical/#integration-points","title":"Integration Points","text":""},{"location":"tools/http-request-technical/#1-tool-registration","title":"1. Tool Registration","text":"<p>Located in: <code>src/influencerpy/core/scouts.py</code></p> <pre><code># Import the tool\nfrom influencerpy.tools.http_tool import http_request\n\n# Add to agent tools list\nif \"http_request\" in tools_config:\n    agent_tools.append(http_request)\n</code></pre>"},{"location":"tools/http-request-technical/#2-prompt-configuration","title":"2. Prompt Configuration","text":"<p>Located in: <code>src/influencerpy/types/prompts.py</code></p> <pre><code>TOOL_INSTRUCTIONS = {\n    \"http_request\": \"\"\"TOOL: http_request\nUse this to fetch and read content from any web URL.\n...\"\"\"\n}\n</code></pre>"},{"location":"tools/http-request-technical/#3-scout-configuration","title":"3. Scout Configuration","text":"<p>User-facing configuration:</p> <pre><code>config = {\n    \"tools\": [\"http_request\"],  # Enable the tool\n    \"orchestration_prompt\": \"...\"\n}\n</code></pre>"},{"location":"tools/http-request-technical/#technical-implementation","title":"Technical Implementation","text":""},{"location":"tools/http-request-technical/#core-function-signature","title":"Core Function Signature","text":"<pre><code>@tool\ndef http_request(\n    url: str, \n    selector: str = None, \n    extract_links: bool = False\n) -&gt; Dict[str, str]:\n    \"\"\"Fetch and parse web content.\"\"\"\n</code></pre>"},{"location":"tools/http-request-technical/#key-features","title":"Key Features","text":""},{"location":"tools/http-request-technical/#1-user-agent-spoofing","title":"1. User Agent Spoofing","text":"<p><pre><code>headers = {\n    'User-Agent': 'Mozilla/5.0 ...'\n}\n</code></pre> Prevents blocking by websites that reject bot requests.</p>"},{"location":"tools/http-request-technical/#2-timeout-protection","title":"2. Timeout Protection","text":"<p><pre><code>response = requests.get(url, timeout=10)\n</code></pre> Prevents hanging on slow/unresponsive servers.</p>"},{"location":"tools/http-request-technical/#3-content-cleaning","title":"3. Content Cleaning","text":"<pre><code># Remove scripts and styles\nfor script in soup([\"script\", \"style\"]):\n    script.decompose()\n\n# Extract clean text\ncontent = soup.get_text(separator=' ', strip=True)\n</code></pre>"},{"location":"tools/http-request-technical/#4-content-truncation","title":"4. Content Truncation","text":"<p><pre><code>max_length = 10000\nif len(content) &gt; max_length:\n    content = content[:max_length] + \"...\"\n</code></pre> Prevents overwhelming the AI model with too much text.</p>"},{"location":"tools/http-request-technical/#5-css-selector-support","title":"5. CSS Selector Support","text":"<pre><code>if selector:\n    elements = soup.select(selector)\n    content = \"\\n\\n\".join(elem.get_text() for elem in elements)\n</code></pre>"},{"location":"tools/http-request-technical/#6-link-extraction","title":"6. Link Extraction","text":"<pre><code>if extract_links:\n    for link in soup.find_all('a', href=True):\n        href = urljoin(url, link['href'])  # Make absolute\n        links.append({\"text\": link_text, \"url\": href})\n</code></pre>"},{"location":"tools/http-request-technical/#error-handling-strategy","title":"Error Handling Strategy","text":"<pre><code>try:\n    # Request logic\nexcept requests.exceptions.Timeout:\n    return {\"url\": url, \"error\": \"Timeout\"}\nexcept requests.exceptions.RequestException as e:\n    return {\"url\": url, \"error\": str(e)}\nexcept Exception as e:\n    return {\"url\": url, \"error\": f\"Parsing error: {e}\"}\n</code></pre>"},{"location":"tools/http-request-technical/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"tools/http-request-technical/#typical-response-times","title":"Typical Response Times","text":"<ul> <li>Simple page: 0.5-2 seconds</li> <li>Complex page: 2-5 seconds</li> <li>Timeout: 10 seconds (then error)</li> </ul>"},{"location":"tools/http-request-technical/#resource-usage","title":"Resource Usage","text":"<ul> <li>Memory: ~10-50 MB per request</li> <li>CPU: Low (parsing is fast)</li> <li>Network: Depends on page size</li> </ul>"},{"location":"tools/http-request-technical/#limitations","title":"Limitations","text":"Aspect Limit Reason Content length 10,000 chars Prevent model overload Links 50 links Prevent excessive data Timeout 10 seconds Prevent hanging JavaScript Not supported Use browser tool instead"},{"location":"tools/http-request-technical/#testing-strategy","title":"Testing Strategy","text":""},{"location":"tools/http-request-technical/#unit-tests","title":"Unit Tests","text":"<pre><code># Mock HTTP responses\nwith patch(\"requests.get\", return_value=mock_response):\n    result = http_request(url=\"...\")\n    assert result[\"content\"] == expected\n</code></pre>"},{"location":"tools/http-request-technical/#integration-tests","title":"Integration Tests","text":"<pre><code># Verify Strands compatibility\nassert hasattr(http_request, 'tool_spec')\nassert http_request.tool_spec['name'] == 'http_request'\n</code></pre>"},{"location":"tools/http-request-technical/#manual-testing","title":"Manual Testing","text":"<pre><code># Run the demo\npython examples/http_tool_demo.py\n</code></pre>"},{"location":"tools/http-request-technical/#security-considerations","title":"Security Considerations","text":""},{"location":"tools/http-request-technical/#1-url-validation","title":"1. URL Validation","text":"<p>The tool trusts the AI agent to provide valid URLs. In production: - Consider URL whitelist/blacklist - Validate URL schemes (http/https only) - Block internal IPs/localhost</p>"},{"location":"tools/http-request-technical/#2-content-safety","title":"2. Content Safety","text":"<ul> <li>The tool extracts text only (no script execution)</li> <li>XSS is not a concern (no rendering)</li> <li>Content is sanitized by text extraction</li> </ul>"},{"location":"tools/http-request-technical/#3-rate-limiting","title":"3. Rate Limiting","text":"<p>Consider adding: - Per-domain rate limits - Request caching - Backoff on errors</p>"},{"location":"tools/http-request-technical/#future-enhancements","title":"Future Enhancements","text":""},{"location":"tools/http-request-technical/#phase-1-stability","title":"Phase 1: Stability","text":"<ul> <li>[x] Basic implementation</li> <li>[x] Error handling</li> <li>[x] Unit tests</li> <li>[ ] Rate limiting per domain</li> <li>[ ] Request caching</li> </ul>"},{"location":"tools/http-request-technical/#phase-2-features","title":"Phase 2: Features","text":"<ul> <li>[ ] Custom headers support</li> <li>[ ] Cookie/session handling</li> <li>[ ] Retry logic with backoff</li> <li>[ ] Robots.txt checking</li> </ul>"},{"location":"tools/http-request-technical/#phase-3-advanced","title":"Phase 3: Advanced","text":"<ul> <li>[ ] JavaScript rendering (Playwright)</li> <li>[ ] Screenshot capture</li> <li>[ ] PDF extraction</li> <li>[ ] Form submission</li> </ul>"},{"location":"tools/http-request-technical/#comparison-with-browser-tool","title":"Comparison with Browser Tool","text":""},{"location":"tools/http-request-technical/#when-to-use-http-request","title":"When to Use HTTP Request","text":"<p>\u2705 Static content only \u2705 Speed is important \u2705 Simple extraction \u2705 Reliable execution needed  </p>"},{"location":"tools/http-request-technical/#when-to-use-browser-tool","title":"When to Use Browser Tool","text":"<p>\u2705 JavaScript required \u2705 Complex interactions \u2705 Form submissions \u2705 Screenshot needed  </p>"},{"location":"tools/http-request-technical/#dependencies","title":"Dependencies","text":""},{"location":"tools/http-request-technical/#required-packages","title":"Required Packages","text":"<pre><code>[project]\ndependencies = [\n    \"beautifulsoup4\",  # HTML parsing\n    \"requests\",        # HTTP client\n    \"strands-agents\",  # Tool decoration\n]\n</code></pre> <p>All dependencies are already in the project - no new installations needed!</p>"},{"location":"tools/http-request-technical/#code-quality","title":"Code Quality","text":""},{"location":"tools/http-request-technical/#type-hints","title":"Type Hints","text":"<pre><code>def http_request(url: str, selector: str = None, extract_links: bool = False) -&gt; Dict[str, str]:\n</code></pre>"},{"location":"tools/http-request-technical/#documentation","title":"Documentation","text":"<ul> <li>\u2705 Comprehensive docstrings</li> <li>\u2705 Inline comments</li> <li>\u2705 Usage examples</li> <li>\u2705 User guide</li> </ul>"},{"location":"tools/http-request-technical/#testing","title":"Testing","text":"<ul> <li>\u2705 Unit tests with mocking</li> <li>\u2705 Integration tests</li> <li>\u2705 Demo script</li> <li>\u2705 Error case coverage</li> </ul>"},{"location":"tools/http-request-technical/#summary","title":"Summary","text":"<p>The HTTP Request tool is: - Fast: No browser overhead - Reliable: Comprehensive error handling - Flexible: CSS selectors for precise extraction - Well-tested: Unit and integration tests - Well-documented: Multiple documentation files - Easy to use: Simple API, clear examples</p> <p>Perfect for most web scraping needs in InfluencerPy! \ud83c\udfaf</p>"},{"location":"tools/http-request/","title":"HTTP Request Tool","text":"<p>The HTTP Request tool allows all agents to fetch and parse web content using Beautiful Soup. This tool is perfect for reading articles, blog posts, documentation, and any web content to create social media posts.</p>"},{"location":"tools/http-request/#features","title":"Features","text":"<ul> <li>Fetch any web page: Read the full content from any URL</li> <li>CSS selectors: Target specific elements using CSS selectors</li> <li>Link extraction: Optionally extract all links from a page</li> <li>Clean text extraction: Automatically removes scripts, styles, and excess whitespace</li> <li>Smart truncation: Limits content to prevent overwhelming the AI model</li> </ul>"},{"location":"tools/http-request/#usage","title":"Usage","text":""},{"location":"tools/http-request/#basic-url-fetch","title":"Basic URL Fetch","text":"<p>Fetch and read the entire content of a web page:</p> <pre><code>from influencerpy.tools.http_tool import http_request\n\nresult = http_request(url=\"https://example.com/article\")\nprint(result[\"content\"])  # Full page text\nprint(result[\"title\"])    # Page title\n</code></pre>"},{"location":"tools/http-request/#using-css-selectors","title":"Using CSS Selectors","text":"<p>Extract specific content using CSS selectors:</p> <pre><code># Extract just the article content\nresult = http_request(\n    url=\"https://example.com/blog/post\", \n    selector=\"article\"\n)\n\n# Extract specific class\nresult = http_request(\n    url=\"https://example.com/page\", \n    selector=\".main-content\"\n)\n\n# Extract by ID\nresult = http_request(\n    url=\"https://example.com/docs\", \n    selector=\"#documentation\"\n)\n</code></pre>"},{"location":"tools/http-request/#extracting-links","title":"Extracting Links","text":"<p>Get all links from a page:</p> <pre><code>result = http_request(\n    url=\"https://example.com\", \n    extract_links=True\n)\n\nfor link in result[\"links\"]:\n    print(f\"{link['text']}: {link['url']}\")\n</code></pre>"},{"location":"tools/http-request/#integration-with-scouts","title":"Integration with Scouts","text":"<p>The HTTP Request tool is available to all agents through the tools configuration. To enable it for a scout:</p>"},{"location":"tools/http-request/#when-creating-a-scout","title":"When Creating a Scout","text":"<pre><code>from influencerpy.core.scouts import ScoutManager\n\nmanager = ScoutManager()\n\nscout = manager.create_scout(\n    name=\"Tech Blog Monitor\",\n    type=\"meta\",\n    config={\n        \"tools\": [\"http_request\"],  # Enable the tool\n        \"orchestration_prompt\": \"Monitor tech blogs and find interesting articles\"\n    },\n    platforms=[\"x\"]\n)\n</code></pre>"},{"location":"tools/http-request/#example-blog-post-scout","title":"Example: Blog Post Scout","text":"<p>Create a scout that monitors specific blog posts:</p> <pre><code>scout = manager.create_scout(\n    name=\"ML Blog Watcher\",\n    type=\"meta\",\n    config={\n        \"tools\": [\"http_request\"],\n        \"orchestration_prompt\": \"\"\"\n            Read the latest posts from machine learning blogs.\n            Use http_request to fetch article content and summarize key insights.\n        \"\"\"\n    },\n    prompt_template=\"Summarize technical articles with key takeaways and practical applications.\",\n    platforms=[\"x\", \"linkedin\"]\n)\n</code></pre>"},{"location":"tools/http-request/#example-link-aggregator-scout","title":"Example: Link Aggregator Scout","text":"<p>Create a scout that finds and analyzes links:</p> <pre><code>scout = manager.create_scout(\n    name=\"Resource Curator\",\n    type=\"meta\",\n    config={\n        \"tools\": [\"http_request\"],\n        \"orchestration_prompt\": \"\"\"\n            Find useful resources from curated lists.\n            Use http_request with extract_links=True to find related content.\n        \"\"\"\n    }\n)\n</code></pre>"},{"location":"tools/http-request/#return-format","title":"Return Format","text":"<p>The tool returns a dictionary with the following structure:</p> <pre><code>{\n    \"url\": str,        # The requested URL\n    \"title\": str,      # Page title (if available)\n    \"content\": str,    # Extracted text content\n    \"links\": [         # List of links (if extract_links=True)\n        {\n            \"text\": str,  # Link text\n            \"url\": str    # Link URL (absolute)\n        }\n    ],\n    \"error\": str       # Error message (if failed)\n}\n</code></pre>"},{"location":"tools/http-request/#error-handling","title":"Error Handling","text":"<p>The tool gracefully handles errors and returns them in the response:</p> <pre><code>result = http_request(url=\"https://invalid-url.example\")\nif \"error\" in result:\n    print(f\"Failed: {result['error']}\")\n</code></pre> <p>Common errors: - Request timeout (10 seconds) - Network connection issues - Invalid URLs - Parsing errors</p>"},{"location":"tools/http-request/#best-practices","title":"Best Practices","text":"<ol> <li>Use CSS selectors when you know the page structure to get cleaner content</li> <li>Check for errors in the response before processing content</li> <li>Combine with other tools like <code>google_search</code> to find URLs first</li> <li>Respect rate limits - don't hammer the same domain repeatedly</li> <li>Content length - The tool automatically truncates content over 10,000 characters</li> </ol>"},{"location":"tools/http-request/#example-workflow","title":"Example Workflow","text":"<p>A typical workflow combining multiple tools:</p> <ol> <li>Use <code>google_search</code> to find interesting articles</li> <li>Use <code>http_request</code> to read the full content</li> <li>Use the LLM to generate a social media post based on the content</li> </ol> <pre><code># This is what the agent does internally:\n# 1. Search for content\nsearch_results = google_search(\"machine learning breakthroughs 2026\")\n\n# 2. Extract URL from results\nurl = extract_first_url(search_results)\n\n# 3. Fetch full content\narticle = http_request(url=url, selector=\"article\")\n\n# 4. Generate post (done by the agent automatically)\n</code></pre>"},{"location":"tools/http-request/#limitations","title":"Limitations","text":"<ul> <li>Timeout: Requests timeout after 10 seconds</li> <li>Content length: Truncated at 10,000 characters</li> <li>Link limit: Maximum 50 links when extract_links=True</li> <li>JavaScript: Cannot execute JavaScript (use browser tool for that)</li> <li>Authentication: Cannot handle login/authenticated pages</li> </ul>"},{"location":"tools/http-request/#comparison-with-browser-tool","title":"Comparison with Browser Tool","text":"Feature http_request browser Speed Fast Slower JavaScript No Yes CSS Selectors Yes Yes Multiple steps No Yes Stability Stable Experimental <p>Use <code>http_request</code> for simple content fetching and the <code>browser</code> tool for complex interactions requiring JavaScript.</p>"}]}